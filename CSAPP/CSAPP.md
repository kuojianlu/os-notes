# CSAPP

## 第1章

### 1.9.2 并发和并行

#### 线程级并发

- 超线程，有时称为同时多线程（simultaneous multi-threading），是一项允许一个CPU执行多个控制流的技术
- 它涉及CPU某些硬件有多个备份，比如程序计数器和寄存器文件，而其他的硬件部分只有一份，比如执行浮点算数运算的单元
- 常规的处理器需要大约20,000个时钟周期做不同线程的切换，而超线程的处理器可以在单个周期的基础上决定要执行哪一个线程。这使得CPU能够更好地利用它的处理资源。比如，假设一个线程必须等到某些数据被装载到高速缓存中，那CPU就可以继续去执行另一个线程
- 举例来说，Intel Core i7处理器可以让每个核执行两个线程，所以一个4核的系统实际上可以并行地执行8个线程

#### 指令级并行

- 现代处理器可以同时执行多条指令的属性称为指令级并行

#### 单指令、多数据并行

- 许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，即SIMD并行

### 1.10 小结

- 操作系统提供三个基本的抽象
  - 文件是对I/O设备的抽象
  - 虚拟内存是对主存核磁盘的抽象
  - 进程是处理器、主存和I/O设备的抽象

## 第2章

### 2.1.3 寻址核字节顺序

- 小端：最低有效字节在最前面
- 大端：最高有效字节在最前面

## 第6章

### 6.4 高速缓存存储器

#### 6.4.1 通用的高速缓存存储器组织结构

<img src="images/高速缓存的通用组织.png" alt="image-20191209235753174" style="zoom:45%;" />

- 一般而言，高速缓存的结构可以用元组`(S, E, B, m)`来描述。高速缓存的大小或容量C指的是所有块的大小的和。标记位和有效位置不包括在内。因此`C=S*E*B`

#### 6.4.2 直接映射高速缓存

- 每个组只有一行的高速缓存称为直接映射高速缓存（direct-mapped cache）

- 高速缓存确定一个请求是否名字，然后抽取出被请求的字的过程，分为三步：

  - 组选择
  - 行匹配
  - 字选择

  <img src="images/直接映射高速缓存中的行匹配和字选择.png" alt="image-20191210003142491" style="zoom:45%;" />

- 标记位和索引位连起来唯一地标识了内存中的每个块

- 因为内存块数大于高速缓存组数，所以多个块会映射到同一个高速缓存组（即它们有相同的组索引）

- 映射到同一个高速缓存组的块由标记位唯一地标识

- 抖动：高速缓存反复地加载和驱逐相同的高速缓存块的组

- 为什么用中间的位来做组索引，而不用高位：

  <img src="images/为什么用中间位来作为高速缓存的组索引.png" alt="image-20191210005155118" style="zoom:45%;" />

#### 6.4.3 组相联高速缓存

- 一个`1<E<C/B`的高速缓存通常称为E路组相联高速缓存（set associative cache）

#### 6.4.4 全相联高速缓存

- 全相联高速缓存（fully associative cache）是由一个包含所有高速缓存行的组（即E=C/B）组成的。全相联高速缓存只有一个组
- 因为高速缓存电路必须并行地搜索许多相匹配的标记，构造一个又大又快的相联高速缓存很困难，而且很昂贵。因此，全相联高速缓存只适合做小的高速缓存，例如虚拟内存系统中的翻译备用缓冲期（TLB），它缓存页表项

#### 6.4.5 有关写的问题

- 一个问题是，怎么将高速缓存的更新同步到下一层存储中
  - 直写（write-through）
    - 直写的缺点是每次写都会引起总线流量
  - 写回（write-back）
    - 写回能显著地减少总线流量，但是它的缺点是增加了复杂性。高速缓存必须为每个高速缓存行维护一个额外的修改位，表明这个高速缓存块是否被修改过

- 另一个问题是如何处理写不命中
  - 写分配（write-allocate）
    - 加载相应的低一层中的块到高速缓存中，然后更新这个高速缓存块。写分配试图利用写的空间局部性，但是缺点是每次不命中都会导致一个块从低一层传送到高速缓存
  - 非写分配
    - 避开高速缓存，直接把这个字写到低一层中

- 直写高速缓存通常是非写分配的。写回高速缓存通常是写分配的
- 建议采用一个使用写回和写分配的高速缓存模型，原因：
  - 通常，由于较长的传送时间，存储器层次结构中较低层的缓存更可能使用写回，而不是直写
  - 它与处理读的方式相对称，因为写回写分配试图利用局部性。因此，我们可以在高层次上开发我们的程序，展示良好的空间和时间局部性，而不是试图为某一个存储器系统进行优化

#### 6.4.6 一个真实的高速缓存层次结构剖析

- i-cache：只保存指令的高速缓存
- d-cache：只保存程序数据的高速缓存
- 统一的高速缓存：既保存指令又包含数据

#### 6.4.7 高速缓存参数的性能影响

- 衡量指标
  - 不命中率
  - 命中率
  - 命中时间：从高速缓存传送一个字到CPU所需的时间，包括组选择、行确认和字选择的时间
  - 不命中处罚：由于不命中所需要的额外的时间

- 高速缓存大小的影响
  - 较大的高速缓存可能会提高命中率
  - 使大存储器运行得更快总是要难一些的，结果，较大的高速缓存可能会增加命中时间。这解释了为什么L1高速缓存比L2高速缓存小，以及为什么L2比L3小

- 块大小的影响
  - 较大的块能利用程序中可能存在的空间局部性，帮助提高命中率
  - 对于给定的高速缓存大小，块越大就意味着高速缓存行越少，这会损害时间局部性比空间局部性更好的程序中的命中率
  - 较大的块对不命中的处罚也有负面影响，因为块越大，传送时间就越长

- 相联度的影响
  - 较高的相联度（也就是E的值较大）会降低高速缓存由于冲突不命中出现抖动的可能性
  - 较高的相联度实现起来很昂贵，而且很难使之速度变快。每一行需要更多的标记位，每一行需要额外的LRU状态位和额外的控制逻辑
  - 较高的相联度会增加命中时间，因为复杂性增加了
  - 还会增加不命中处罚，因为选择牺牲行的复杂性也增加了

- 写策略的影响
  - 直写高速缓存比较容易实现，而且能使用独立于高速缓存的写缓冲区，用来更新内存
  - 此外，读不命中开销没这么大，因为它们不会触发内存写
  - 写回高速缓存引起的传送比较少，它允许更多的到内存的带宽用于执行DMA的I/O设备
  - 此外，越往层次结构下面走，传送时间增加，减少传送的数量就变得更加重要。一般而言，高速缓存越往下面，越可能使用写回而不是直写

#### 6.5 编写高速缓存友好的代码

- 一般而言，如果一个高速缓存的块大小为B字节，那么一个步长为k的引用模式（k是以字为单位的）平均每次循环迭代会有min(1, (wordsize*k)/B)次缓存不命中。当k=1时，它取最小值
- 因此
  - 对局部变量的反复引用是友好的，因为编译器能够将它们缓存在寄存器文件中（时间局部性）
  - 步长为1的引用模式是友好的，因此存储器层次结构中所有层次上的缓存都是将数据存储为连续的块（空间局部性）

### 6.6 综合：高速缓存对程序性能的影响

#### 6.6.3 在程序中利用局部性

- 将注意力集中在内循环上，大部分计算和内存访问都发生在这里
- 通过按照数据对象存储在内存中的顺序、以步长为1的来读数据，从而使得程序中的空间局部性最大
- 一旦从存储器中读入了一个数据对象，就尽可能多地使用它，从而使得程序中的时间局部性最大

## 第8章 异常控制流

- 异常控制流（Exceptional Control Flow，ECF）
- 异常控制流发生在计算机系统的各个层次
  - 硬件层
  - 操作系统层
  - 应用层

### 8.1 异常

- 异常是异常控制流的一种形式，它一部分由硬件实现，一部分由操作系统实现
- 异常包括：
  - 和当前指令的执行直接相关的事件：虚拟内存缺页、算术溢出、一条指令试图处以零
  - 和当前指令的执行没有关系的事件：一个系统定时器产生信号、一个I/O请求完成

- 当异常处理程序完成处理后，根据引起异常的事件类型，会发生以下3种情况的一种
  - 处理程序将控制返回给当前指令
  - 处理程序将控制返回给下一条指令
  - 处理程序终止被中断的线程

#### 8.1.1 异常处理

- 异常号
  - 由处理器的设计者分配的：被零除、缺页、内存访问违例、断点、算术运算溢出
  - 由操作系统内核的设计者分配的：系统调用、来自外部I/O的信号

- 异常表
  - 异常表的起始地址放在一个叫做异常表基址寄存器的特殊CPU寄存器里
- 异常与过程调用的区别
  - 过程调用时，在跳转到处理程序之前，处理器将返回地址压入栈中。然而，根据异常的类型，返回地址要么是当前指令，要么是下一条指令
  - 处理器也把一些额外的处理器状态压到栈里，在处理程序返回时，重新开始执行被中断的程序需要这些状态。比如，x86-64系统会将包含当前条件码的EFLAGS寄存器和其他内容压入栈中
  - 如果控制从用户程序转移到内核，所有这些项目都被压到内核栈中，而不是压到用户栈中
  - 异常处理程序运行在内核模式下，这意味着它们对所有的系统资源都有完全的访问权限

- 一旦硬件触发了异常，剩下的工作就是由异常处理程序在软件中完成。在处理程序处理完事件之后，它通过执行一条特殊的“从中断返回”指令，可选地返回到被中断的程序，该指令将适当的状态弹回到处理器的控制和数据寄存器中，如果异常中断的是一个用户程序，就将状态恢复为用户模式，然后将控制返回给被中断的程序

#### 8.1.2 异常的类别

<img src="images/异常的类别.png" alt="image-20191213224937407" style="zoom:50%;" />

- 中断（interrupt）
  - 硬件中断的异常处理程序常常称为中断处理程序
  - I/O设备，例如网络适配器、磁盘控制器和定时器芯片，通过向处理器芯片上的一个引脚发信号，并将异常号放到系统总线上，来触发中断，这个异常号标识了引起中断的设备
  - 在当前指令完成执行后，处理器注意到中断引脚的电压变高了，就从系统总线读取异常号，然后调用适当的中断处理程序

- 陷阱和系统调用（trap）
  - 陷阱是有意的异常，是执行一条指令的结构。陷阱最重要的用途是在用户程序和内核之间提供一个像过程一样的接口，叫做系统调用
  - 处理器提供了一条特殊的syscall n指令

- 故障（fault）
  - 故障是由错误情况引起的，它可能能够被故障处理程序修正。当故障发生时，处理器将控制转移给故障处理程序。如果处理程序能够修正这个错误情况，它就将控制返回到引起故障的指令，从而重新执行它。否则，处理程序返回到内核中的abort例程，abort例程会终止引起故障的应用程序
  - 一个典型的故障示例是缺页异常

- 终止（abort）
  - 终止是不可恢复的致命错误造成的结果，通常是一些硬件错误，比如DRAM或者SRAM位被损坏时发生的奇偶错误。处理程序将控制返回给一个abort例程，该例程会终止这个应用程序

#### 8.1.3 Linux/x86-64系统中的异常

- 故障和终止
  - 除法错误：浮点异常（Float exception）
  - 一般保护故障：通常是因为一个程序引用了一个未定义的虚拟内存区域，或者因为程序试图写一个只读的文本段。断故障（Segmentation fault）
  - 机器检查：机器检查是在导致故障的指令执行中检测到致命的硬件错误时发生的

- 系统调用

  ```c
  int main()
  {
    write(1, "hello, world\n", 13);
    _exit(0);
  }
  ```

  ```assembly
  .section .data
  string:
  	.ascii "hello, world\n"
  string_end:
  	.equ len, string_end - string
  .section .text
  .global main
  main:
  	movq $1, %rax # write is system call 1
  	movq $1, %rdi # Arg1: stdout has descriptor 1
  	movq $string, %rsi # Arg2
  	movq $len, %rdx # Arg3
  	syscall
  	
  	movq $60, %rax # _exit is system call 60
  	movq $0, $rdi # Arg1
  	syscall
  ```

### 8.2 进程

#### 8.2.3 私有地址空间

<img src="images/进程地址空间.png" alt="image-20191213235331386" style="zoom:50%;" />

#### 8.2.4 用户模式和内核模式

- 处理器通常是用某个控制寄存器中的一个模式位来提供这种功能，该寄存器描述了进程当前享有的特权。当设置了模式位时，进程就运行在内核模式中

- Linux提供了一种聪明的机制，叫做/proc文件系统，它允许用户模式进程访问内核数据结构的内容。/proc文件系统将许多内核数据结构的内容输出为一个用户程序可以读的文本文件的层次结构。比如，可以使用/proc文件系统找出一般的系统属性，如/proc/cpuinfo，或者某个特殊的进程使用的内存段`/proc/<process-id>/maps`。2.6版本的Linux内核引入/sys文件系统，它输出关于系统总线和设备的额外的低层信息

#### 8.2.5 上下文切换

- 内核为每个进程维持一个上下文。上下文就是内核重新启动一个被抢占的进程所需的状态。它由一些对象的值组成，这些对象包括通用目的寄存器、浮点寄存器、程序计数器、用户栈、状态寄存器、内核栈和各种内核数据结构，比如描述地址空间的页表、包含有关当前进程信息的进程表，以及保护进程已打开文件的信息的文件表
- 当内核代表用户执行系统调用时，可能会发生上下文切换
- 中断也可能引发上下文切换

### 8.4 进程控制

#### 8.4.2 创建和终止进程

- 从程序员的角度，我们可以认为进程总是处于下面三种状态之一
  - 运行：进程要么在CPU上执行，要么在等待被执行且最终会被内核调度
  - 停止。进程的执行被挂起，且不会被调度。当收到SIGSTOP、SIGTSTP、SIGTTIN或者SIGTTOU信号时，进程就停止，并且保持停止知道它收到一个SIGCONT信号，在这个时刻，进程再次开始运行（信号是一种软件中断的形式）
  - 终止。进程永远地停止了。进程会因为三种原因终止：1）收到一个信号，该信号的默认行为是终止进程；2）从主程序返回；3）调用exit函数

<img src="images/嵌套fork的进程图.png" alt="image-20191214002007636" style="zoom:50%;" />

#### 8.4.3 回收子进程

- 当一个进程由于某种原因终止时，内核并不是立即把它从系统中清除。相反，进程被保存在一种已终止的状态中，知道被它的父进程回收。当父进程回收已终止的子进程时，内核将子进程的退出状态传递给父进程，然后抛弃已终止的进程，从此时开始，该进程就不存在了。一个终止了但还未被回收的进程称为僵死进程（zombie）

- 如果一个父进程终止了，内核会安排init进程称为它的孤儿进程的养父。init进程不会终止，是所有进程的祖先。如果父进程没有回收它的僵死子进程就终止了，那么内核会安排init进程去回收它们。不过，长时间运行的程序，比如shell或者服务器，总是应该回收它们的僵死子进程。即使僵死子进程没有运行，它们仍然消耗系统的内存资源

- 参考：[Linux回收子进程](https://www.jianshu.com/p/8be8b636c9c8)

- `pid_t waitpid(pit_t pid, int* statusp, int options)`

- 使用waitpid函数不按照特定的顺序回收僵死子进程

  ```c
  #include "csapp.h"
  #define N 2
  
  int main()
  {
    int status, i;
    pid_t pid;
    
    for (i = 0; i < N; i++)
      if ((pid = Fork()) == 0)
        exit(100+i);
    
    while ((pid = waitpid(-1, &status, 0)) > 0) {
      if (WIFEXITED(status))
        printf("child %d terminated normally with exit status=%d\n", pid, WEXITSTATUS(status));
      else
        printf("child %d terminated abnormally\n", pid);
    }
    
    if (errno != ECHILD)
      unix_error("waitpid error");
    
    exit(0)
  }
  ```

#### 8.4.4 让进程休眠

- 如果请求的时间量已经到了，sleep函数返回0，否则返回还剩下的要休眠的秒数。后一种情况是可能的，如果因为sleep函数被一个信号而过早地返回
- pause函数让调用者休眠，直到该进程收到一个信号

#### 8.4.5 加载并运行程序

- `int execve(const char *filename, const char *argv[], const char *envp[])`

- 在execve加载了filename之后，它调用7.9节中描述的启动代码。启动代码设置栈，并将控制传递给新程序的主函数。当main开始执行时，用户栈的组织结构如图：

  <img src="images/一个新程序开始时用户栈的典型组织结构.png" alt="image-20191214123933426" style="zoom:50%;" />

- fork和execve的区别

  - fork函数在新的子进程中运行相同的程序，新的子进程是父进程的一个复制品
  - execve函数在当前进程的上下文中加载并运行一个新的程序，它会覆盖当前进程的地址空间，但并没有创建一个新的进程。新的程序仍然有相同的PID，并且继承了调用execve函数时已打开的所有文件描述符

### 8.5 信号

- Linux信号是一种更高层（相比于低层异常机制）的软件形式的异常，它运行进程和内核中断其他进程

- 一个信号就是一条小消息，它通知进程系统中发生了一个某种类型的事件

- Linux系统上支持的30种不同类型的信号

  <img src="images/Linux信号.png" alt="image-20191214124450628" style="zoom:45%;" />

- 每种信号类型都对应于某种系统事件。低层的硬件异常是由内核异常处理程序处理的，正常情况下，对用户进程而言是不可见的

- 信号提供了一种机制，通知用户进程发生了这些异常。比如，如果一个进程试图除以0，那么内核就发送给它一个SIGFPE信号。一个进程可以通过向另一个进程发送SIGKILL信号强制终止它

#### 8.5.1 信号术语

- 传送一个信号到目的进程是由两个不同步骤组成的
  - 发送信号
    - 内核通过更新目的进程上下文中的某个状态，发送一个信号给目的进程
    - 发送信号的原因可以有如下两种原因：1）内核检测到一个系统事件，比如除零错误或者子进程终止；2）一个进程调用了kill函数，显式地要求内核发送一个信号给目的进程。一个进程可以发送信号给它自己
  - 接收信号

- 一个发出而没有被接收的信号叫做待处理信号（pending signal）。在任何时刻，一种类型至多只会有一个待处理信号。一个进程可以有选择性地阻塞接收某种信号。当一种信号被阻塞时，它仍可以被发送，但是产生的待处理信号不会被接收，直到进程取消对这种信号的阻塞
- 一个待处理信号最多只能被接收一次。内核为每个进程在pending位向量中维护着待处理信号的集合，而在blocked位向量中维护着被阻塞的信号集合。只要传送了一个类型为k的信号，内核就会设置pending中的第k位，而只要接收了一个类型为k的信号，内核就会清除pending中的第k位

#### 8.5.2 发送信号

- 进程组
  - 每个进程都只属于一个进程组
  - 默认地，一个子进程和它的父进程同属于一个进程组

#### 8.5.3 接收信号

- 当内核把进程p从内核模式切换到用户模式时，它会检查进程p的未被阻塞的待处理信号的集合（pending&~blocked）。如果这个集合为空，那么内核将控制传递到p的逻辑控制流的下一条指令。然而，如果集合是非空的，那么内核选择集合中的某个信号k（通常是最小的k），并且强制p接收信号k。收到这个信号会触发进程采取某种行为。一旦进程完成了这个行为，那么控制就传递回p的逻辑控制流的下一条指令
- 每个信号类型都有一个预定义的默认行为，是下面的一种
  - 进程终止
  - 进程终止并转储内存
  - 进程停止直到被SIGCONT信号重启
  - 进程忽略该信号

- 进程可以使用signal函数修改和信号相关联的默认行为
  - `sighandler_t signal(int signum, sighandler_t handler)`
  - 如果handler不是SIG_IGN或SIG_DFL，那么handler就是用户定义的函数的地址，这个函数被称为信号处理程序
  - 当一个进程捕获了一个类型为k的信号时，会调用为信号k设置的处理程序，一个整数参数被设置为k。这个参数允许同一个处理函数捕获不同类型的信号

- 信号处理程序可以被其他信号处理程序中断

#### 8.5.4 阻塞和解除阻塞信号

- Linux提供阻塞信号的隐式和显式的机制
  - 隐式阻塞机制：内核默认阻塞任何当前处理程序正在处理信号类型的待处理信号
  - 显式阻塞机制：应用程序可以使用sigprocmask函数和它的辅助函数，明确地阻塞和解除选定的信号

#### 8.5.5 编写信号处理程序

- 安全的信号处理
  - 处理程序要尽可能简单
  - 在处理程序中只调用异步信号安全的函数。所谓异步信号安全的函数能够被信号处理程序安全地调用，原因有二：要么它是可重入的（例如只访问局部变量），要么它不能被信号处理程序中断
  - 保存和恢复errno。在进入处理程序时把errno保存在一个局部变量中，在处理程序返回前恢复它。这样做的目的是避免干扰主程序中其他依赖errno的部分
  - 阻塞所有的信号，保护共享全局数据结构的访问。这条规则的原因是从主程序访问一个数据结构d通常需要一系列的指令，如果指令序列被访问d的处理程序中断，那么处理程序可能会发现d的状态不一样，得到不可预知的结果
  - 用volatile声明全局变量。考虑一个处理程序和一个main函数，它们共享一个全局变量g。处理程序更新g，main周期性地读g。对于一个优化编译器而言，main中g的值看上去从来没有变化过，因为使用缓存在寄存器中的g副本来满足对g的每次引用是很安全的。如果这样，main函数可能永远都无法看到处理程序更新过的值
  - 用sig_atomic_t声明标志。在常见的处理程序中，处理程序会写全局标志来记录收到了信号。主程序周期性地读这个标志，响应信号，再清除该标志。对于通过这种方式来共享的标志，C提供一种整型数据类型sig_atomic_t，对它的读和写保证会是原子的（不可中断的），因为可以用一条指令来实现它们`volatile sig_atomic_t flag`，因此它们是不可中断的，所以可以安全地读和写sig_atomic_t变量，而不需要暂时阻塞信号。注意，这里对原子性的保证只适用于单个的读和写，不适用于像flag++或flag=flag+10这样的更新，因为它们可以需要多条指令

- 正确的信号处理
  - 存在一个待处理信号只是暗示自进程最后一次收到一个信号以来，至少已经有一个这种类型的信号被发送了

- 可移植的信号处理

#### 8.5.6 同步流以避免讨厌的并发错误

#### 8.5.7 显式地等待信号

- `int sigsuspend(const sigset_t *mask)`
- sigsuspend函数暂时用mask替换当前的阻塞集合，然后挂起该进程，直到收到一个信号，其行为要么是允许一个处理程序，要么是终止该进程。如果它的行为是终止，那么该进程不从suspend返回就直接终止。如果它的行为是运行一个处理程序，那么sigsuspend从处理程序返回，恢复调用sigsuspend时原有的阻塞集合

### 8.6 非本地跳转

- 非本地跳转（nonlocal jump），它将控制直接从一个函数转移到另一个当前正在执行的函数，而不需要经过正常的调用-返回序列

- `int setjmp(jmp_buf env)`函数在env缓冲区保存当前调用环境，以供后面的longjmp使用，并返回0.调用环境包括程序计数器、栈指针和通用目的寄存器

- `void longjmp(jmp_buf env, int retval)`函数从env缓冲区中恢复调用环境，然后出发一个从最近一次初始化env的setjmp调用的返回。然后setjmp返回，并带有非零的返回值retval

- setjmp只被调用一次，但返回多次：一次是当第一次调用setjmp，而调用环境保存在缓冲区env中时，一次是为每个相应的longjmp调用。另一方面，longjmp函数被调用一次，但从不返回

- 非本地跳转的一个重要应用就是允许从一个深层嵌套的函数调用中立即返回，通常是由检测到某个错误情况引起的。如果在一个深层嵌套的函数调用中发现了一个错误情况，我们可以使用非本地跳转直接返回到一个普通的本地化的错误处理程序，而不是费力地解开调用栈

  ```c
  #include "csapp.h"
  
  jmp_buf buf;
  
  int error1 = 0;
  int error2 = 1;
  
  void foo(void), bar(void);
  
  int main()
  {
    switch(setjmp(buf)) {
      case 0:
        foo();
        break;
      case 1:
        printf("Detected an error1 condition in foo\n");
        break;
      case 2:
        printf("Detected an error2 condition in foo\n");
        break;
      default:
        printf("Unknown error condition in foo\n");
    }
    exit(0);
  }
  
  void foo(void)
  {
    if (error1)
      longjmp(buf, 1);
    bar();
  }
  
  void bar(void)
  {
    if (error2)
      longjmp(buf, 2);
  }
  ```

- C++和Java提供的异常机制是较高层次的，是C语言中setjmp和longjmp函数的更加结构化的版本。可以把try语句中catch子句看作类似于setjmp函数。相应地，throw语句就类似于longjmp函数

## 第9章 虚拟内存

### 9.3 虚拟内存作为缓存的工具

- 在任意时刻，虚拟页面的集合都分为三个不相交的子集

  - 未分配的：VM系统还未分配（或者创建）的页。未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间
  - 缓存的：当前已缓存在物理内存中的已分配页
  - 未缓存的：未缓存在物理内存中的已分配页

  <img src="images/一个VM系统是如何使用主存作为缓存的.png" alt="image-20191214161408494" style="zoom:50%;" />

#### 9.3.1 DRAM缓存的组织结构

- 因为大的不命中处罚和访问第一个字节的开销，虚拟页往往很大，通常是4KB-2MB
- 由于大的不命中处罚，DRAM缓存是全相联的，即任何虚拟页都可以放置在任何物理页中
- 不命中时的替换策略页很重要，因为替换了虚拟页的处罚页非常之高。因此，于硬件对SRAM缓存相比，操作系统对DRAM缓存使用了更复杂精密的替换算法
- 因为对磁盘的访问时间很长，DRAM缓存总是使用写回，而不是直写

### 9.4 虚拟内存作为内存管理的工具

- 简化链接
  - 独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的何处。这样的一致性极大地简化了链接器的设计和实现，允许链接器生成完全链接的可执行文件，这些可执行文件是独立于物理内存中代码和数据的最终位置的
- 简化加载
  - 要把目标文件中的.text和.data节加载到一个新创建的进程中，Linux加载器为代码和数据段分配虚拟页，把它们标记为无效的，将页表条目指向目标文件中适当的位置。加载器从不从磁盘到内存实际复制任何数据。在每个页初次被引用时，要么是CPU取指令时引用的，要么是一条正在执行的指令引用一个内存位置时引用的，虚拟内存会按照需要自动地调入数据页
- 简化共享
  - 操作系统通过将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进程共享这部分代码的一个副本。而不是在每个进程中都包括单独的内核和C标准库的副本

- 简化内存分配
  - 当一个运行在用户进程中的程序要求额外的堆空间时，操作系统分配一个适当数字（例如k）个连续的虚拟内存页面，并且将它们映射到物理内存中任意位置的k个任意的物理页面。由于页表的工作方式，操作系统没有必要分配k个连续的物理内存页面。页面可以随机地分散在物理内存中

### 9.5 虚拟内存作为内存保护的工具

<img src="images/用虚拟内存来提供页面级的内存保护.png" alt="image-20191214165756152" style="zoom:50%;" />

### 9.6 地址翻译

- 当页面命中时，CPU硬件执行的步骤
  - 第1步：处理器生成一个虚拟地址，并把它传送给MMU
  - 第2步：MMU生成PTE（Page Table Entry）地址，并从高速缓存/主存请求得到它
  - 第3步：高速缓存/主存向MMU返回PTE
  - 第4步：MMU构造物理地址，并把它传送给高速缓存/主存
  - 第5步：高速缓存/主存返回所请求的数据字处理器

<img src="images/页面命中和缺页的操作图.png" alt="image-20191214193637411" style="zoom:50%;" />

- 页面命中完全是由硬件来处理的，与之不同的是，处理缺页要求硬件和操作系统协作完成：
  - 第1步到第3步：同上
  - 第4步：PTE中的有效位是零，所以MMU触发了一次异常，传递CPU中的控制到操作系统内核中的缺页异常处理程序
  - 第5步：缺页处理程序确定出物理内存中的牺牲页，如果这个页面已经被修改了，则把它换出到磁盘
  - 第6步：缺页处理程序页面调入新的页面，并更新内存中的PTE
  - 第7步：缺页处理程序返回到原来的进程，再次执行导致缺页的指令。CPU将引起缺页的虚拟地址重新发送给MMU

#### 9.6.1 结合高速缓存和虚拟内存

<img src="images/将VM与物理寻址的高速缓存结合起来.png" alt="image-20191214195422045" style="zoom:50%;" />

#### 9.6.2 利用TLB加速地址翻译

- MMU中的TLB，Translation Lookaside Buffer，翻译后备缓冲器
- TLB是一个小的，虚拟地址的缓存，其中每一行都保存着一个由单个PTE组成的块。TLB通常由高度的相联度

